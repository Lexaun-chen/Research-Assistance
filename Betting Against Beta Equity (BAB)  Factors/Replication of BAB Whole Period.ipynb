{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:42:13.853544Z",
     "start_time": "2024-11-14T15:42:12.170237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wrds\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sas7bdat import SAS7BDAT\n",
    "import datetime as dt\n",
    "from pandas.tseries.offsets import *\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import pyreadstat\n",
    "from scipy import stats\n",
    "import dask.dataframe as dd"
   ],
   "id": "3034ab15112e2b72",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/dask/dataframe/__init__.py:49: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:42:13.953144Z",
     "start_time": "2024-11-14T15:42:13.949706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def wavg(group, avg_name, weight_name):\n",
    "    d = group[avg_name]\n",
    "    w = group[weight_name]\n",
    "    try:\n",
    "        return (d * w).sum() / w.sum()\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def normalize_k(group):\n",
    "\n",
    "    beta_rank = group['rank']\n",
    "    beta_avg_rank = group['rank_avg']\n",
    "\n",
    "    diff_sum = abs(beta_rank - beta_avg_rank).sum()\n",
    "    k = 2 / diff_sum if diff_sum != 0 else 0\n",
    "\n",
    "    return k\n",
    "\n",
    "def vector_vwt(group, vector_name, weight_name):\n",
    "    scalar = (group[vector_name] * group[weight_name]).sum()\n",
    "    return scalar\n"
   ],
   "id": "d3bd20c3e69be9a7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:42:14.230948Z",
     "start_time": "2024-11-14T15:42:14.087351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AQR_path = \"/Users/benben/Desktop/RA/Task4 Betting against Beta/BAB For US Equity.xlsx\"\n",
    "BAB_AQR = pd.read_excel(AQR_path)\n",
    "BAB_AQR['date'] = pd.to_datetime(BAB_AQR['date'], format='%Y%m', errors='coerce')\n",
    "BAB_AQR = BAB_AQR.dropna(subset=['date'])\n",
    "BAB_AQR['month'] = BAB_AQR['date'].dt.to_period('M')\n",
    "BAB_AQR['month'] = BAB_AQR['month'].astype(str)\n",
    "\n",
    "BAB_AQR = BAB_AQR[['month','US_BAB']]"
   ],
   "id": "91c17798aaa03aa1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:42:14.248599Z",
     "start_time": "2024-11-14T15:42:14.237877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ff_path =\"/Users/benben/Desktop/RA/Task4 Betting against Beta/F-F_Research_Data_Factors_Monthly.CSV\"\n",
    "_ff = pd.read_csv(ff_path)\n",
    "_ff.columns =['month','mkt-rf','smb','hml','rf']\n",
    "_ff['month'] = pd.to_datetime(_ff['month'], format='%Y%m').dt.strftime('%Y-%m')\n",
    "_ff['month'] = _ff['month'].astype(str)\n",
    "_ff[['mkt-rf', 'smb', 'hml','rf']] = _ff[['mkt-rf', 'smb', 'hml','rf']]/100"
   ],
   "id": "8d8a8f0e38b144d3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:44:12.107299Z",
     "start_time": "2024-11-14T15:42:14.256727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "crsp_path = \"/Users/benben/Desktop/RA/Task4 Betting against Beta/crsp daily.sas7bdat\"\n",
    "crsp, meta = pyreadstat.read_sas7bdat(crsp_path)\n",
    "crsp.columns = crsp.columns.str.lower()\n",
    "crsp[['permno','permco','shrcd','exchcd',]] = crsp[['permno','permco','shrcd','exchcd']].astype(int)\n",
    "crsp['date'] = pd.to_datetime(crsp['date']).dt.date\n",
    "crsp = crsp[(crsp['shrcd']==10)|(crsp['shrcd']==11)]\n",
    "\n",
    "dfs = crsp.dropna(subset=['ret','prc','shrout'])\n",
    "\n",
    "\"\"\"\n",
    "Derive market cap\n",
    "\"\"\"\n",
    "dfs['mkt_cap'] = dfs['shrout'] * abs(dfs['prc'])\n",
    "dfs['date'] = pd.to_datetime(dfs['date'], errors='coerce')\n",
    "dfs.dropna(subset=['date'], inplace=True)\n"
   ],
   "id": "68fc64db399b8d42",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/677262450.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs['mkt_cap'] = dfs['shrout'] * abs(dfs['prc'])\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/677262450.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs['date'] = pd.to_datetime(dfs['date'], errors='coerce')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/677262450.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs.dropna(subset=['date'], inplace=True)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:58:53.955267Z",
     "start_time": "2024-11-14T15:44:12.175332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "time_periods = {\n",
    "    '1926-1959': ('1926-01-01', '1960-01-01'),\n",
    "    '1960-1993': ('1960-01-01', '1994-01-01'),\n",
    "    '1994-2024': ('1994-01-01', '2013-12-31')\n",
    "}\n",
    "\n",
    "dfs_ny = []\n",
    "Bab_Port = []\n",
    "\n",
    "for period, (start_date, end_date) in time_periods.items():\n",
    "    dfs_period = dfs[(dfs['date'] >= start_date) & (dfs['date'] <= end_date)]\n",
    "\n",
    "    \"\"\"\n",
    "    Estimating ex ante betas\n",
    "    \n",
    "    We first need to derive \n",
    "     \n",
    "    1. estimated volatilities for individual stocks and the market use:\n",
    "                                                        one-year (252d) rolling window, at least 120 trading data\n",
    "    \n",
    "    2, correlation between stocks and the market use:\n",
    "                                        five-year (1260d) rolling window, at least 750 trading data\n",
    "    \"\"\"\n",
    "\n",
    "    dfs_period = dfs_period.sort_values(by=['permno','date'])\n",
    "    dfs_period['month'] = dfs_period['date'].dt.to_period('M')\n",
    "\n",
    "    dfs_period['log_ret'] = np.log(dfs_period['ret'] + 1)\n",
    "    dfs_period['log_ret3d'] = dfs_period.groupby('permno')['log_ret'].rolling(window=3).sum().reset_index(level=0, drop=True)\n",
    "    dfs_period['stk_month_ret'] = np.exp(dfs_period.groupby(['permno','month'])['log_ret'].transform('sum')) -1\n",
    "\n",
    "    mkt_ret = dfs_period.groupby('date').apply(wavg, 'ret', 'mkt_cap').reset_index(name='mkt_ret')\n",
    "    mkt_ret = mkt_ret.sort_values(by=['date'])\n",
    "    mkt_ret['date'] = pd.to_datetime(mkt_ret['date'], errors='coerce')\n",
    "    mkt_ret.dropna(subset=['date'], inplace=True)\n",
    "    mkt_ret['month'] = mkt_ret['date'].dt.to_period('M')\n",
    "    \n",
    "    mkt_ret['log_mkt_ret'] = np.log(1 + mkt_ret['mkt_ret'])\n",
    "    mkt_ret['log_mkt_ret3d'] = mkt_ret['log_mkt_ret'].rolling(window=3).sum().reset_index(level=0, drop=True)\n",
    "    mkt_ret['mtk_month_ret'] = np.exp(mkt_ret.groupby(['month'])['log_mkt_ret'].transform('sum')) -1\n",
    "    \n",
    "    mkt_ret['mkt_volatility'] = mkt_ret['log_mkt_ret'].rolling(window=252, min_periods=120).std()\n",
    "\n",
    "\n",
    "    dfs_period = dd.merge(dfs_period, mkt_ret[['date', 'mkt_ret','log_mkt_ret3d','mtk_month_ret', 'mkt_volatility']], on='date', )\n",
    "    \n",
    "    # dfs = dfs[dfs['exchcd'] == 1|dfs['exchcd'] == 2|dfs['exchcd'] == 3]\n",
    "    \n",
    "    \n",
    "    vol_corr_results = []\n",
    "\n",
    "    dfs_period = dfs_period.dropna(subset=['log_ret3d', 'log_mkt_ret3d'])\n",
    "    \n",
    "    for permno, group in dfs_period.groupby('permno'):\n",
    "        group = group.set_index('date')\n",
    "    \n",
    "        # 要求至少120天数据用于波动率计算，至少750天用于相关性计算\n",
    "        if len(group) < 750:\n",
    "            continue\n",
    "    \n",
    "        # 1年窗口（252天）计算波动率\n",
    "        group['volatility'] = group['log_ret'].rolling(window=252, min_periods=120).std()\n",
    "    \n",
    "        # 5年窗口（1260天）计算相关性\n",
    "        group['correlation'] = group['log_ret3d'].rolling(window=1260, min_periods=750).corr(group['log_mkt_ret3d'])\n",
    "    \n",
    "        vol_corr_results.append(group[['permno', 'volatility', 'correlation','mkt_volatility']])\n",
    "    \n",
    "    # 合并所有股票的波动率和相关性数据\n",
    "    vol_corr_df = pd.concat(vol_corr_results).dropna().reset_index()\n",
    "    \n",
    "    vol_corr_df['pre_ranking_beta'] = vol_corr_df['correlation'] * (vol_corr_df['volatility'] / vol_corr_df['mkt_volatility'])\n",
    "    \n",
    "    dfs_period = pd.merge(dfs_period,vol_corr_df[['date','permno','pre_ranking_beta']], on=['date','permno'], how='left')\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Shrink the time series estimate of beta  toward the cross-sectional mean\n",
    "    Use predetermined shrinkage factor\n",
    "    \"\"\"\n",
    "    \n",
    "    wi = 0.6\n",
    "    beta_xs = 1\n",
    "    \n",
    "    dfs_period['shrink_beta'] = wi * dfs_period['pre_ranking_beta'] + (1 - wi) * beta_xs\n",
    "    \n",
    "    dfs_ny.append(dfs_period[dfs_period['exchcd'] == 1])\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate the median beta of asset classes and months.\n",
    "    \n",
    "    Group based on the comparison between:\n",
    "    \n",
    "                                 1. Each stock's monthly average beta at the end of the month \n",
    "      \n",
    "                                 2. The monthly median beta according to its exchcd.\n",
    "                                 \n",
    "    Rebalance the portfolio monthly.\n",
    "    \"\"\"\n",
    "    \n",
    "    dfs_period['median_beta'] = dfs_period.groupby('month')['shrink_beta'].transform('median')\n",
    "    \n",
    "    dfs_period['avg_beta'] = dfs_period.groupby(['month', 'permno'])['shrink_beta'].transform('mean')\n",
    "    \n",
    "    \n",
    "    dfs_period['beta_group'] = dfs_period.apply(lambda x: 'low' if x['avg_beta'] <= x['median_beta'] else 'high', axis=1)\n",
    "    dfs_period['beta_group'] = np.where((pd.isna(dfs_period['avg_beta']) | pd.isna(dfs_period['median_beta'])),np.nan ,dfs_period['beta_group'] )\n",
    "    dfs_period.dropna(subset=['beta_group'], inplace=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    Derive the securities' monthly beta ascending rank.\n",
    "    \n",
    "    Derive ranked weight for each security every month.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #只保留个股每个月的最后一条数据\n",
    "    dfs_period.sort_values(by=['permno','month','date'], inplace=True)\n",
    "    dfs_month = dfs_period.drop_duplicates(subset=['permno','month'],keep='last')\n",
    "    \n",
    "    dfs_month['lmktcap'] = dfs_month.groupby('permno')['mkt_cap'].shift(1)\n",
    "    dfs_month['lmktcap'] = np.where(dfs_month['lmktcap'].isna(), dfs_month['mkt_cap']/(1 + dfs_month['stk_month_ret']),dfs_month['lmktcap'])\n",
    "    \n",
    "    dfs_month = dfs_month[['month','permno','stk_month_ret','shrink_beta','beta_group','lmktcap','mkt_cap','mtk_month_ret']]\n",
    "    \n",
    "    dfs_month.sort_values(by=['month','shrink_beta'], inplace=True)\n",
    "    dfs_month['rank'] = dfs_month.groupby(['month'])['shrink_beta'].rank(method='first')\n",
    "    \n",
    "    dfs_month['rank_avg'] = dfs_month.groupby(['month'])['rank'].transform('mean')\n",
    "    \n",
    "    Normalize = dfs_month.groupby(['month']).apply(normalize_k).reset_index(name='normalizing_cons')\n",
    "    \n",
    "    dfs_month = pd.merge(dfs_month, Normalize, on=['month'], how='left')\n",
    "    \n",
    "    dfs_month['rank_wgt'] = np.where(\n",
    "        dfs_month['rank'] <= dfs_month['rank_avg'],\n",
    "        dfs_month['normalizing_cons'] * np.maximum(0, dfs_month['rank_avg'] - dfs_month['rank']),\n",
    "        dfs_month['normalizing_cons'] * np.maximum(0, dfs_month['rank'] - dfs_month['rank_avg'])\n",
    "    )\n",
    "\n",
    "    port_month_ret = dfs_month.groupby(['beta_group','month']).apply(wavg,'stk_month_ret','lmktcap').reset_index(name='port_month_ret')\n",
    "    \n",
    "    _ff['month'] = _ff['month'].astype(str)\n",
    "    \n",
    "    port_month_ret['month'] = port_month_ret['month'].astype(str)\n",
    "    \n",
    "    port_month_ret = pd.merge(port_month_ret, _ff[['month','rf']], on=['month'], how='inner')\n",
    "    \n",
    "    port_month_ret['port_excess_ret'] = port_month_ret['port_month_ret']-port_month_ret['rf']\n",
    "    \n",
    "    dfs_port = dfs_month[['month','permno','lmktcap','stk_month_ret','beta_group','rank_wgt','shrink_beta']]\n",
    "    \n",
    "    dfs_port['month'] = dfs_port['month'].astype(str)\n",
    "    \n",
    "    dfs_port = pd.merge(dfs_port, _ff[['month','rf']], on=['month'], how='inner')\n",
    "    \n",
    "    dfs_port.dropna(inplace=True)\n",
    "    \"\"\"\n",
    "    Construct BAB portfolio\n",
    "    \n",
    "    Rescale both portfolios to have a beta of one at portfolio formation\n",
    "    \n",
    "    Self-financing zero-beta portfolio \n",
    "        long the low-beta portfolio and shortsell the high-beta portfolio\n",
    "    \"\"\"\n",
    "    \n",
    "    Beta = dfs_port.groupby(['month','beta_group']).apply(vector_vwt, 'shrink_beta','rank_wgt' ).reset_index(name='beta')\n",
    "    Beta['lag_beta'] = Beta.groupby('beta_group')['beta'].shift(1)\n",
    "    \n",
    "    Beta_port = Beta.pivot(index='month', columns='beta_group', values='lag_beta').reset_index()\n",
    "    Beta_port.rename(columns={'high': 'high_beta', 'low': 'low_beta'}, inplace=True)\n",
    "    \n",
    "    Return_port = dfs_port.groupby(['month','beta_group']).apply(vector_vwt, 'stk_month_ret','rank_wgt' ).reset_index(name='port_ret')\n",
    "    Return_port = Return_port.pivot(index='month', columns='beta_group', values='port_ret').reset_index()\n",
    "    Return_port.rename(columns={'high': 'high_ret', 'low': 'low_ret'}, inplace=True)\n",
    "    \n",
    "    Return_port.dropna(inplace=True)\n",
    "    Beta_port.dropna(inplace=True)\n",
    "    Return_port['month'] = Return_port['month'].astype(str)\n",
    "    Beta_port['month'] = Beta_port['month'].astype(str)\n",
    "    \n",
    "    \n",
    "    bab_port = pd.merge(Return_port, Beta_port, on=['month'], how='inner')\n",
    "    \n",
    "    bab_port = pd.merge(bab_port, _ff[['month','rf','mkt-rf']], on=['month'], how='left')\n",
    "    \n",
    "    bab_port['high_bab'] = 1 / bab_port['high_beta'] * (bab_port['high_ret'] - bab_port['rf'])\n",
    "    bab_port['low_bab'] = 1 / bab_port['low_beta'] * (bab_port['low_ret'] - bab_port['rf'])\n",
    "    \n",
    "    bab_port['bab_ret'] = bab_port['low_bab'] - bab_port['high_bab']\n",
    "    \n",
    "    bab_port.dropna(inplace=True)\n",
    "    bab_port.reset_index(inplace=True)\n",
    "    bab_port = bab_port[['month','bab_ret']]\n",
    "\n",
    "    Bab_Port.append(bab_port)"
   ],
   "id": "66e549ee8cf63bc7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  mkt_ret = dfs_period.groupby('date').apply(wavg, 'ret', 'mkt_cap').reset_index(name='mkt_ret')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_month['lmktcap'] = dfs_month.groupby('permno')['mkt_cap'].shift(1)\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_month['lmktcap'] = np.where(dfs_month['lmktcap'].isna(), dfs_month['mkt_cap']/(1 + dfs_month['stk_month_ret']),dfs_month['lmktcap'])\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:132: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  Normalize = dfs_month.groupby(['month']).apply(normalize_k).reset_index(name='normalizing_cons')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:142: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  port_month_ret = dfs_month.groupby(['beta_group','month']).apply(wavg,'stk_month_ret','lmktcap').reset_index(name='port_month_ret')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_port['month'] = dfs_port['month'].astype(str)\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:168: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  Beta = dfs_port.groupby(['month','beta_group']).apply(vector_vwt, 'shrink_beta','rank_wgt' ).reset_index(name='beta')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  Return_port = dfs_port.groupby(['month','beta_group']).apply(vector_vwt, 'stk_month_ret','rank_wgt' ).reset_index(name='port_ret')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  mkt_ret = dfs_period.groupby('date').apply(wavg, 'ret', 'mkt_cap').reset_index(name='mkt_ret')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_month['lmktcap'] = dfs_month.groupby('permno')['mkt_cap'].shift(1)\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_month['lmktcap'] = np.where(dfs_month['lmktcap'].isna(), dfs_month['mkt_cap']/(1 + dfs_month['stk_month_ret']),dfs_month['lmktcap'])\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:132: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  Normalize = dfs_month.groupby(['month']).apply(normalize_k).reset_index(name='normalizing_cons')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:142: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  port_month_ret = dfs_month.groupby(['beta_group','month']).apply(wavg,'stk_month_ret','lmktcap').reset_index(name='port_month_ret')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_port['month'] = dfs_port['month'].astype(str)\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:168: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  Beta = dfs_port.groupby(['month','beta_group']).apply(vector_vwt, 'shrink_beta','rank_wgt' ).reset_index(name='beta')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  Return_port = dfs_port.groupby(['month','beta_group']).apply(vector_vwt, 'stk_month_ret','rank_wgt' ).reset_index(name='port_ret')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  mkt_ret = dfs_period.groupby('date').apply(wavg, 'ret', 'mkt_cap').reset_index(name='mkt_ret')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_month['lmktcap'] = dfs_month.groupby('permno')['mkt_cap'].shift(1)\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_month['lmktcap'] = np.where(dfs_month['lmktcap'].isna(), dfs_month['mkt_cap']/(1 + dfs_month['stk_month_ret']),dfs_month['lmktcap'])\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:132: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  Normalize = dfs_month.groupby(['month']).apply(normalize_k).reset_index(name='normalizing_cons')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:142: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  port_month_ret = dfs_month.groupby(['beta_group','month']).apply(wavg,'stk_month_ret','lmktcap').reset_index(name='port_month_ret')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_port['month'] = dfs_port['month'].astype(str)\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:168: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  Beta = dfs_port.groupby(['month','beta_group']).apply(vector_vwt, 'shrink_beta','rank_wgt' ).reset_index(name='beta')\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/2811898436.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  Return_port = dfs_port.groupby(['month','beta_group']).apply(vector_vwt, 'stk_month_ret','rank_wgt' ).reset_index(name='port_ret')\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:59:02.377874Z",
     "start_time": "2024-11-14T15:59:02.238675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Bab_Port = pd.concat(Bab_Port, ignore_index=True)\n",
    "\n",
    "Test = pd.merge(Bab_Port,BAB_AQR,how='left',on=['month'])\n",
    "Test = Test.dropna(subset=['bab_ret','US_BAB'])\n",
    "\n",
    "BAB_corr = stats.pearsonr(Test['bab_ret'], Test['US_BAB'])[0]\n",
    "print(BAB_corr)\n",
    "\n",
    "new_row = pd.DataFrame({'month': ['Correlation'], 'bab_ret': [BAB_corr]})\n",
    "Bab_Port = pd.concat([Bab_Port, new_row], ignore_index=True)\n",
    "\n",
    "Bab_Port.rename(columns={'bab_ret':'BAB Factor'}, inplace=True)\n",
    "\n",
    "Bab_Port.to_excel('./BAB factor 1926-2013.xlsx', index=False, sheet_name='BAB factor from 1926-2013')\n"
   ],
   "id": "654554080ac93028",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9595993350836289\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:59:42.361662Z",
     "start_time": "2024-11-14T15:59:05.761570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    " A replication of Table 3 in Frazzini and Pedersen (2014)\n",
    "\"\"\"\n",
    "\n",
    "def Beta_group (row):\n",
    "    if (row['beta0']<=row['shrink_beta']) and (row['shrink_beta']<row['beta10']):\n",
    "        group='P1'\n",
    "    elif (row['beta10']<=row['shrink_beta']) and (row['shrink_beta']<row['beta20']):\n",
    "        group='P2'\n",
    "    elif (row['beta20']<=row['shrink_beta']) and (row['shrink_beta']<row['beta30']):\n",
    "        group='P3'\n",
    "    elif (row['beta30']<=row['shrink_beta']) and (row['shrink_beta']<row['beta40']):\n",
    "        group='P4'\n",
    "    elif (row['beta40']<=row['shrink_beta']) and (row['shrink_beta']<row['beta50']):\n",
    "        group='P5'\n",
    "    elif (row['beta50']<=row['shrink_beta']) and (row['shrink_beta']<row['beta60']):\n",
    "        group='P6'\n",
    "    elif (row['beta60']<=row['shrink_beta']) and (row['shrink_beta']<row['beta70']):\n",
    "        group='P7'\n",
    "    elif (row['beta70']<=row['shrink_beta']) and (row['shrink_beta']<row['beta80']):\n",
    "        group='P8'\n",
    "    elif (row['beta80']<=row['shrink_beta']) and (row['shrink_beta']<row['beta90']):\n",
    "        group='P9'\n",
    "    elif (row['beta90']<=row['shrink_beta']) and (row['shrink_beta']<row['beta100']):\n",
    "        group='P10'\n",
    "    else:\n",
    "        group=np.nan\n",
    "    return group\n",
    "\n",
    "\n",
    "dfs_ny = pd.concat(dfs_ny, ignore_index=True)\n",
    "dfs_ny = dfs_ny.groupby(['month'])['shrink_beta'] \\\n",
    "    .describe(percentiles=[0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1]).reset_index()\n",
    "\n",
    "dfs_ny = dfs_ny.rename(columns={'0%':'beta0', '10%':'beta10','20%':'beta20','30%':'beta30','40%':'beta40','50%':'beta50','60%':'beta60','70%':'beta70', '80%':'beta80', '90%':'beta90','100%':'beta100'})\n",
    "\n",
    "dfs_ny = dfs_ny.drop(['count','mean','std','min','max'], axis=1)\n",
    "dfs_decile = dfs_port[['month','permno','lmktcap','stk_month_ret','shrink_beta']]\n",
    "\n",
    "dfs_decile['month'] = dfs_decile['month'].astype(str)\n",
    "dfs_ny['month'] = dfs_ny['month'].astype(str)\n",
    "dfs_decile = pd.merge(dfs_decile, dfs_ny, on=['month'], how='inner')\n",
    "\n",
    "dfs_decile['beta_group'] = dfs_decile.apply(Beta_group, axis=1)"
   ],
   "id": "1addfbfd48fe6d9b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/321046752.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs_decile['month'] = dfs_decile['month'].astype(str)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:59:42.933011Z",
     "start_time": "2024-11-14T15:59:42.592423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "port_month_ret = dfs_decile.groupby(['beta_group','month']).apply(wavg,'stk_month_ret','lmktcap').reset_index(name='port_month_ret')\n",
    "\n",
    "_ff['month'] = _ff['month'].astype(str)\n",
    "port_month_ret['month'] = port_month_ret['month'].astype(str)\n",
    "\n",
    "port_month_ret = pd.merge(port_month_ret, _ff[['month','rf']], on=['month'], how='inner')\n",
    "\n",
    "port_month_ret['port_excess_ret'] = port_month_ret['port_month_ret']-port_month_ret['rf']\n",
    "\n",
    "port_month_ret = port_month_ret.dropna(subset=['beta_group','port_excess_ret'], axis=0)\n",
    "\n",
    "port = port_month_ret.pivot(index='month', columns='beta_group', values='port_excess_ret').reset_index()\n",
    "\n",
    "bab_port['month'] = bab_port['month'].astype(str)\n",
    "port = pd.merge(port, _ff, on='month', how='inner')\n",
    "port = pd.merge(port, bab_port[['month','bab_ret']], on='month', how='inner')\n",
    "port.dropna(inplace=True)"
   ],
   "id": "b1bdb7fe776a30ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/3405380354.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  port_month_ret = dfs_decile.groupby(['beta_group','month']).apply(wavg,'stk_month_ret','lmktcap').reset_index(name='port_month_ret')\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:59:47.668550Z",
     "start_time": "2024-11-14T15:59:47.647142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_alpha(portfolio_return, factors):\n",
    "    X = sm.add_constant(factors)\n",
    "    model = sm.OLS(portfolio_return, X).fit()\n",
    "    alpha = model.params['const']  # 截距项\n",
    "    alpha_se = model.bse[0]\n",
    "    alpha_t_stat = alpha / alpha_se\n",
    "    return alpha, alpha_t_stat\n",
    "\n",
    "\n",
    "Excess_returen = {}\n",
    "Excess_tstats = {}\n",
    "CAPM_alphas = {}\n",
    "CAPM_tstats = {}\n",
    "\n",
    "for column in ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10','bab_ret']:\n",
    "\n",
    "    mean_excess_ret = port[column].mean()\n",
    "    std_excess_ret = port[column].std()\n",
    "    n = len(port[column])\n",
    "    se_excess_ret = std_excess_ret / np.sqrt(n)\n",
    "    t_stat_excess_ret = mean_excess_ret / se_excess_ret\n",
    "    ret_tstat_with_brackets = f\"({t_stat_excess_ret:.2f})\"\n",
    "\n",
    "    Excess_returen[column] = mean_excess_ret * 100\n",
    "    Excess_tstats[column] = ret_tstat_with_brackets\n",
    "\n",
    "    capm_alpha, capm_tstat = calculate_alpha(port[column], port[['mkt-rf']])\n",
    "    capm_tstat_with_brackets = f\"({capm_tstat:.2f})\"\n",
    "    CAPM_alphas[column] = capm_alpha * 100\n",
    "    CAPM_tstats[column] = capm_tstat_with_brackets\n",
    "\n",
    "# 将 alpha 和 t-statistics 转换为 DataFrame\n",
    "excess_df = pd.DataFrame(Excess_returen, index=['Excess return'])\n",
    "excess_tstat_df = pd.DataFrame(Excess_tstats, index=['     '])\n",
    "capm_alpha_df = pd.DataFrame(CAPM_alphas, index=['CAPM alpha'])\n",
    "capm_tstat_df = pd.DataFrame(CAPM_tstats, index=['     '])\n",
    "\n",
    "# 合并成一张宽表\n",
    "results_df = pd.concat([excess_df,excess_tstat_df,capm_alpha_df,capm_tstat_df],axis=0)\n",
    "results_df.rename(columns={'bab_ret':'BAB', 'P1':'Low beta','P10':'High beta'}, inplace=True)"
   ],
   "id": "9777cb9621d4a1bc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/1589414078.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_se = model.bse[0]\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/1589414078.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_se = model.bse[0]\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/1589414078.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_se = model.bse[0]\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/1589414078.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_se = model.bse[0]\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/1589414078.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_se = model.bse[0]\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/1589414078.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_se = model.bse[0]\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/1589414078.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_se = model.bse[0]\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/1589414078.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_se = model.bse[0]\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/1589414078.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_se = model.bse[0]\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/1589414078.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_se = model.bse[0]\n",
      "/var/folders/vt/x4z4r3fd0xg5nszdcjd244900000gn/T/ipykernel_1748/1589414078.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  alpha_se = model.bse[0]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T15:59:51.751634Z",
     "start_time": "2024-11-14T15:59:51.735172Z"
    }
   },
   "cell_type": "code",
   "source": "results_df.to_excel('Table 3.xlsx', index=True, sheet_name='US equities returns, 1926-2024')",
   "id": "ae80e6208b75b71c",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PycharmEnv",
   "language": "python",
   "name": "pycharmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
